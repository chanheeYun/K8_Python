{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYJeA4fpcGNk"
      },
      "source": [
        "# Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AZqhmeccW7p"
      },
      "source": [
        "\n",
        "## 1. 미국 대통령에 관한 정보를 담은 파일을 읽고 이를 처리하는 프로그램을 작성하세요. 그로버 클리블랜드처럼 비연속적인 임기를 지낸 대통령들은 각각의 임기가 따로 나열되어 있습니다.\n",
        "\n",
        "* President 클래스를 작성하고, 대통령의 이름, 각 임기의 시작 및 종료 연도를 추출하는 메서드를 작성하세요. 또한, 대통령이 총 4년 이상을 재임했는지(연속적이든 아니든)를 확인하는 메서드를 작성하세요.\n",
        "\n",
        "* 현재 재임 중인 대통령(예: 조 바이든, 종료 연도가 없는 경우)의 처리를 포함해야 합니다.\n",
        "\n",
        "* 파일: https://github.com/dbwebb-se/vlinux/blob/master/example/grep/presidents.txt\n",
        "\n",
        "* 파일의 각 줄에는 대통령의 이름과 그들이 재임한 연도가 쉼표로 구분되어 나열되어 있습니다.\n",
        "\n",
        "### President 클래스\n",
        "\n",
        "* 생성자 (__init__): President 객체를 초기화하며 대통령의 이름을 저장하고 process_term 메서드를 사용하여 각 임기를 처리합니다. 임기의 목록은 문자열로 전달되며, 각 문자열은 \"1789-1797\" 또는 \"1885-1889, 1893-1897\"처럼 표현됩니다.\n",
        "\n",
        "> 힌트: 생성자에서 list comprehension을 사용하여 각 임기 문자열을 __process_term 메서드를 사용해 (start_year, end_year) 튜플로 변환하세요. 이렇게 하면 대통령의 임기 데이터를 쉽게 접근하고 조작할 수 있습니다.\n",
        "\n",
        "* __process_term 메서드: 대통령 임기를 나타내는 문자열(예: \"1789-1797\")을 받아 시작 및 종료 연도를 정수로 변환하는 튜플로 바꿉니다. 종료 연도가 없으면(예: 현재 대통령인 경우) 현재 연도를 할당합니다.\n",
        "\n",
        "> 힌트: 문자열 분할(term.split('-'))을 사용해 임기를 시작 연도와 종료 연도로 나누세요. 종료 연도가 없으면 datetime.now().year를 사용하여 현재 연도를 할당하세요. 이 메서드는 완료된 임기와 진행 중인 임기 모두를 처리할 수 있도록 합니다.\n",
        "\n",
        "* is_served_multiple 메서드: 대통령이 총 4년 이상 재임했는지 또는 여러 임기를 지냈는지 확인합니다. 모든 임기를 합산하여 총 재임 기간이 4년을 초과하는지 확인합니다.\n",
        "\n",
        "> 힌트: generator expression을 사용해 각 임기의 종료 연도와 시작 연도 사이의 차이를 합산하여 총 재임 기간을 계산하세요.\n",
        "\n",
        "### 함수\n",
        "\n",
        "read_presidents_from_file 함수: 파일에서 각 줄에 대통령의 이름과 재임 기간이 포함된 데이터를 읽고, President 객체의 목록을 생성합니다.\n",
        "\n",
        "> 힌트: split(', ', 1)을 사용해 이름과 임기를 분리하세요. 그런 다음 임기를 목록으로 나누고 President 생성자에 전달하세요. 파일이 없는 경우 try-except 블록을 사용하여 예외 처리를 하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            " 2020\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "print(type(datetime.now().year))\n",
        "\n",
        "s, e = '2020-'.split('-')\n",
        "print(e, s)\n",
        "print(type(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RNYIQCYnt9ca"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class President:\n",
        "    def __init__(self, name: str, terms: list):\n",
        "        self.name = name\n",
        "        self.terms = [self.__process_term(term) for term in terms]\n",
        "    \n",
        "    def __process_term(self, term: str):\n",
        "        start_year, end_year = term.split('-')\n",
        "        start_year = int(start_year)\n",
        "        if end_year == '': \n",
        "            end_year = datetime.now().year\n",
        "        else:\n",
        "            end_year = int(end_year)\n",
        "        return start_year, end_year\n",
        "\n",
        "    def is_served_multiple(self) -> bool:\n",
        "        total = sum(end - start for start, end in self.terms)\n",
        "        return total >= 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WchTnVn0eCIh"
      },
      "outputs": [],
      "source": [
        "def read_presidents_from_file(file_path: str) -> list:\n",
        "    result = []\n",
        "    # try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            name, terms = line.rstrip().split(', ', 1)\n",
        "            president = next((p for p in result if p.name == name), None)\n",
        "            if president:\n",
        "                new_terms = president.terms.append(president.__process_term(terms))\n",
        "                new_president = President(name, new_terms)\n",
        "                result[result.index(president)] = new_president\n",
        "            else:\n",
        "                result.append(President(name, terms))\n",
        "    # except Exception as e:\n",
        "    #     print('파일을 찾을 수 없습니다')\n",
        "    \n",
        "    return result       \n",
        "                \n",
        "            \n",
        "    # result = []\n",
        "    # file_content = open(file_path)\n",
        "    # for line in file_content:\n",
        "    #     name, terms = line.strip().split(', ')\n",
        "    #     p = President(name, terms)\n",
        "    #     result.append(p)\n",
        "    #     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "19HbTZd5XI4i"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m presidents \u001b[38;5;241m=\u001b[39m \u001b[43mread_presidents_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maip_file_io\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpresidents.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m president \u001b[38;5;129;01min\u001b[39;00m presidents:\n",
            "Cell \u001b[1;32mIn[40], line 13\u001b[0m, in \u001b[0;36mread_presidents_from_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m             result[result\u001b[38;5;241m.\u001b[39mindex(president)] \u001b[38;5;241m=\u001b[39m new_president\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m             result\u001b[38;5;241m.\u001b[39mappend(\u001b[43mPresident\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterms\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#     print('파일을 찾을 수 없습니다')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "Cell \u001b[1;32mIn[39], line 6\u001b[0m, in \u001b[0;36mPresident.__init__\u001b[1;34m(self, name, terms)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, terms: \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__process_term(term) \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m terms]\n",
            "Cell \u001b[1;32mIn[39], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, terms: \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__process_term\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m terms]\n",
            "Cell \u001b[1;32mIn[39], line 9\u001b[0m, in \u001b[0;36mPresident.__process_term\u001b[1;34m(self, term)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__process_term\u001b[39m(\u001b[38;5;28mself\u001b[39m, term: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 9\u001b[0m     start_year, end_year \u001b[38;5;241m=\u001b[39m term\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m     start_year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(start_year)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_year \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: \n",
            "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ],
      "source": [
        "presidents = read_presidents_from_file('aip_file_io\\presidents.txt')\n",
        "\n",
        "count = 0\n",
        "for president in presidents:\n",
        "    if president.is_served_multiple():\n",
        "        count += 1\n",
        "\n",
        "# assert count == 18\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGbPfQJEc5pl"
      },
      "source": [
        "\n",
        "## 2. TextAnalyzer 클래스를 작성하세요. 이 클래스에는 word_frequency() 메서드가 있으며, 생성 시 제공되는 텍스트 파일을 읽고 파일에 있는 각 단어의 빈도를 반환합니다. 단어는 소문자로 변환되어야 하고, 구두점은 무시되어야 합니다. 파일을 찾지 못했을 경우의 예외 처리를 적절히 처리하세요.\n",
        "\n",
        "> 파일 URL: https://gist.github.com/phillipj/4944029\n",
        "\n",
        "\n",
        "# 클래스 TextAnalyzer\n",
        "\n",
        "* 생성자 (init): TextAnalyzer 클래스의 인스턴스를 초기화합니다. 이 생성자는 하나의 인자 file_path를 받으며, 이 인자는 분석할 텍스트 파일의 경로를 나타냅니다. 이 인자는 나중에 다른 메서드에서 사용될 수 있도록 인스턴스 변수로 저장됩니다.\n",
        "\n",
        "> 힌트: 클래스를 인스턴스화할 때, 유효한 파일 경로를 생성자에게 인자로 전달하는지 확인하세요. 이 파일 경로는 word_frequency 메서드에서 사용됩니다.\n",
        "\n",
        "* word_frequency(self): 텍스트 파일을 처리하여 파일 내의 각 단어를 빈도로 매핑하는 딕셔너리를 반환합니다. 이 메서드는 파일의 내용을 읽고, 모든 텍스트를 소문자로 변환하여 대소문자 구분 없는 비교를 보장하며, 구두점을 제거하여 실제 단어에 집중합니다. 그런 다음, 내용을 단어로 분리하고, 각 단어의 출현 빈도를 계산하여 딕셔너리에 저장합니다.\n",
        "\n",
        "> 힌트: 이 메서드는 파일을 읽고 분석하여 각 단어가 몇 번 등장했는지를 카운팅하는 역할을 합니다. 텍스트는 대소문자 구분 없이 처리되어야 하며, 구두점과 같은 불필요한 문자는 제거되어야 합니다. 메서드는 각 단어와 그에 해당하는 빈도를 포함하는 딕셔너리를 반환합니다. 또한, 파일이 존재하지 않을 경우를 처리하는 예외처리도 해야 합니다.\n",
        "\n",
        "> 구두점 제거\n",
        "```python\n",
        "words = ''.join([char if char.isalnum() or char.isspace() else ' ' for char in file_content]).split()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OXPr0YxXJwx"
      },
      "outputs": [],
      "source": [
        "class TextAnalyzer:\n",
        "    def __init__(self, file_path: str):\n",
        "        pass\n",
        "\n",
        "    def word_frequency(self) -> dict:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trMw_2Fdh97P"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def read_expected_result(expected_result_file):\n",
        "  try:\n",
        "      with open(expected_result_file, 'rb') as f:\n",
        "          expected_result = pickle.load(f)\n",
        "  except FileNotFoundError:\n",
        "      print(\"Expected result file not found.\")\n",
        "      expected_result = None\n",
        "  finally:\n",
        "      return expected_result\n",
        "\n",
        "input_file_path = \"alice_in_wonderland.txt\"\n",
        "expected_result_file = \"expected_result.pkl\"\n",
        "\n",
        "analyzer = TextAnalyzer(input_file_path)\n",
        "result = analyzer.word_frequency()\n",
        "\n",
        "expected_result = read_expected_result(expected_result_file)\n",
        "sorted_result = sorted(result.items(), key=lambda x: (-x[1], x[0]))\n",
        "assert sorted_result == expected_result\n",
        "\n",
        "\n",
        "missing_file_path = \"missing.txt\"\n",
        "expected_result_file = \"missing_output.pkl\"\n",
        "analyzer = TextAnalyzer(missing_file_path)\n",
        "\n",
        "expected_result = read_expected_result(expected_result_file)\n",
        "output = analyzer.word_frequency()\n",
        "\n",
        "assert output == expected_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INqFk2K5c7ks"
      },
      "source": [
        "## 3. 다음을 계산하는 메서드를 포함한 CountryStatistics 클래스를 작성하세요:\n",
        "\n",
        "* GDP가 가장 높은 상위 5개 국가: 이 메서드는 GDP가 가장 높은 상위 5개 국가의 이름을 반환하며, GDP 값은 쉼표로 형식화됩니다.\n",
        "* 기대 수명이 가장 긴 상위 5개 국가: 이 메서드는 기대 수명이 가장 긴 상위 5개 국가의 이름을 반환합니다.\n",
        "* 인구 밀도가 가장 높은 상위 5개 국가: 이 메서드는 인구 밀도가 가장 높은 상위 5개 국가의 이름을 반환합니다.\n",
        "\n",
        "* 파일: https://gist.github.com/vr-23/d6a4a0aadcf3a2640091ca43c25e1955#file-world-data-2023-csv\n",
        "\n",
        "### CountryStatistics 클래스\n",
        "\n",
        "* __clean_numeric_data(value: str): 문자열을 입력으로 받아 쉼표, 달러 기호, 백분율 기호를 제거하고 숫자 값을 float으로 반환합니다. 입력을 변환할 수 없으면 0.0을 반환합니다.\n",
        "\n",
        "> 힌트: 이 함수는 쉼표나 달러 기호가 포함된 CSV 파일의 숫자 데이터를 처리하는 데 유용합니다.\n",
        "빈 문자열이나 숫자가 아닌 값을 처리할 수 있도록 예외 처리에 신경 쓰세요.\n",
        "\n",
        "* __load_data(filename: str): CSV 파일에서 국가 데이터를 로드하고 데이터를 파싱하여 Country 객체를 생성합니다. 정리된 데이터는 self.countries 리스트에 저장됩니다.\n",
        "\n",
        "> 힌트: csv.reader를 사용하여 CSV 파일을 한 줄씩 읽습니다.\n",
        "첫 번째 행은 헤더이므로 건너뜁니다.\n",
        "모든 숫자 데이터 필드에 대해 __clean_numeric_data를 호출하여 데이터를 저장하기 전에 정확하게 정리된 데이터를 확인하세요.\n",
        "GDP, 기대 수명, 인구 등의 열 인덱스를 정확하게 매핑하세요.\n",
        "\n",
        "* top_5_gdp(): GDP가 가장 높은 상위 5개 국가의 이름과 쉼표로 형식화된 GDP 값을 포함한 튜플 목록을 반환합니다.\n",
        "\n",
        "> 힌트: 국가들을 gdp 속성 기준으로 내림차순 정렬하세요.\n",
        "슬라이싱 ([:5])을 사용하여 상위 5개 항목을 선택하세요.\n",
        "국가 이름과 형식화된 GDP 값을 반환하세요.\n",
        "\n",
        "* top_5_life_expectancy(): 기대 수명이 가장 긴 상위 5개 국가의 이름과 그들의 기대 수명 값을 포함한 튜플 목록을 반환합니다.\n",
        "\n",
        "> 힌트: 국가들을 기대 수명(life_expectancy) 기준으로 내림차순 정렬하세요.\n",
        "슬라이싱 ([:5])을 사용하여 상위 5개 항목을 추출하세요.\n",
        "기대 수명 값은 형식화할 필요가 없으므로 있는 그대로 반환하세요.\n",
        "\n",
        "* countries_by_density(): 인구 밀도가 가장 높은 상위 5개 국가의 이름과 인구 밀도를 반환합니다.\n",
        "\n",
        "> 힌트: 국가들을 인구 밀도(density) 속성 기준으로 내림차순 정렬하세요.\n",
        "슬라이싱 ([:5])을 사용하여 상위 5개 항목을 선택하세요.\n",
        "인구 밀도 값은 정수이므로 형식화할 필요가 없습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-O90MGn4Hmy"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "class Country:\n",
        "    def __init__(self, name: str, density: int, land_area: int, gdp: float, life_expectancy: float, population: int):\n",
        "        self.name = name\n",
        "        self.density = density\n",
        "        self.land_area = land_area\n",
        "        self.gdp = gdp\n",
        "        self.life_expectancy = life_expectancy\n",
        "        self.population = population\n",
        "\n",
        "class CountryStatistics:\n",
        "    def __init__(self, filename: str):\n",
        "        pass\n",
        "\n",
        "    def __clean_numeric_data(self, value: str) -> float:\n",
        "        pass\n",
        "\n",
        "    def __load_data(self, filename: str):\n",
        "        pass\n",
        "\n",
        "    def top_5_gdp(self):\n",
        "        pass\n",
        "\n",
        "    def top_5_life_expectancy(self):\n",
        "        pass\n",
        "\n",
        "    def countries_by_density(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtu5YK_Vx623"
      },
      "outputs": [],
      "source": [
        "expected_gdp_output = [\n",
        "    (\"United States\", \"21,427,700,000,000\"),\n",
        "    (\"China\", \"19,910,000,000,000\"),\n",
        "    (\"Japan\", \"5,081,769,542,380\"),\n",
        "    (\"Germany\", \"3,845,630,030,824\"),\n",
        "    (\"United Kingdom\", \"2,827,113,184,696\")\n",
        "]\n",
        "\n",
        "expected_life_expectancy_output = [\n",
        "    (\"San Marino\", 85.4),\n",
        "    (\"Japan\", 84.2),\n",
        "    (\"Switzerland\", 83.6),\n",
        "    (\"Spain\", 83.3),\n",
        "    (\"Singapore\", 83.1)\n",
        "]\n",
        "\n",
        "expected_density_output = [\n",
        "    (\"Monaco\", 26337),\n",
        "    (\"Singapore\", 8358),\n",
        "    (\"Bahrain\", 2239),\n",
        "    (\"Vatican City\", 2003),\n",
        "    (\"Maldives\", 1802)\n",
        "]\n",
        "\n",
        "expected_average_population = 57\n",
        "\n",
        "stats = CountryStatistics('./countries.csv')\n",
        "\n",
        "for (expected_country, expected_gdp), (result_country, result_gdp) in zip(expected_gdp_output, stats.top_5_gdp()):\n",
        "    assert expected_country == result_country\n",
        "    assert expected_gdp == result_gdp\n",
        "\n",
        "for (expected_country, expected_life), (result_country, result_life) in zip(expected_life_expectancy_output, stats.top_5_life_expectancy()):\n",
        "    assert expected_country == result_country\n",
        "    assert expected_life == result_life\n",
        "\n",
        "for (expected_country, expected_density), (result_country, result_density) in zip(expected_density_output, stats.countries_by_density()):\n",
        "    assert expected_country == result_country\n",
        "    assert expected_density == result_density\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtGlz5V2Nhmw"
      },
      "source": [
        "## 4. 파일에서 숫자 데이터를 처리하고 합계, 평균, 최소값, 최대값 및 중앙값과 같은 기본 통계를 계산하는 메서드를 제공하는 FileProcessor 클래스를 작성하세요.\n",
        "\n",
        "### FileProcessor 클래스\n",
        "\n",
        "* 생성자: FileProcessor 객체를 초기화합니다. 파일 이름을 입력으로 받아 저장하고, 이후에 파일에서 읽어온 숫자 데이터를 저장할 빈 리스트 self.data를 초기화합니다.\n",
        "\n",
        "> 힌트: 이 메서드는 파일을 읽고 처리할 준비를 합니다. 파일 경로는 저장되지만, 데이터는 다른 메서드에서 요청할 때까지 로드되지 않습니다.\n",
        "\n",
        "* __read_file(self): 파일에서 데이터를 읽습니다. 파일을 읽기 모드로 열고, 각 줄에서 불필요한 문자를 제거한 후 데이터를 실수로 변환합니다. 이 처리된 데이터를 self.data에 저장합니다.\n",
        "\n",
        "> 힌트: 이 메서드를 사용하여 필요한 경우에만 데이터를 지연 로드합니다. FileNotFoundError 및 ValueError와 같은 파일 관련 오류를 처리하여 파일 읽기가 견고하게 이루어지도록 합니다.\n",
        "\n",
        "* calc_sum(self): 숫자 데이터의 합계를 계산합니다. 데이터가 아직 읽히지 않았다면 먼저 _read_file 메서드를 호출합니다. 데이터가 사용 가능해지면 값을 합산하고 결과를 소수점 한 자리까지 반올림하여 반환합니다.\n",
        "\n",
        "> 힌트: 계산을 수행하기 전에 파일이 읽혔는지 확인하세요. 내장된 sum() 함수를 사용하여 코드를 간소화할 수 있습니다. 빈 파일이 있을 수 있으므로 _read_file이 성공적으로 호출된 경우에만 이 메서드가 제대로 작동합니다.\n",
        "\n",
        "* calc_average(self): 숫자 데이터의 평균(산술 평균)을 계산합니다. 필요한 경우 _read_file을 호출하여 데이터가 사용 가능한지 확인합니다. 데이터가 없을 경우 ZeroDivisionError를 발생시킵니다.\n",
        "\n",
        "> 힌트: 평균은 데이터의 합계를 항목 수로 나눈 값입니다. 나누기를 수행하기 전에 항목이 있는지 확인하여 0으로 나누는 오류를 방지하세요.\n",
        "\n",
        "* calc_min(self): 데이터셋에서 최소값을 계산하고 반환합니다. 아직 파일을 읽지 않았다면 파일을 읽어 데이터를 확인합니다. 데이터가 없을 경우 ValueError를 발생시킵니다.\n",
        "\n",
        "> 힌트: Python의 내장 min() 함수를 사용하여 최소값을 찾습니다. 데이터가 없는 경우 적절하게 예외를 발생시켜야 합니다.\n",
        "\n",
        "* calc_max(self): 데이터셋에서 최대값을 계산하고 반환합니다. 필요한 경우 데이터를 읽고, 데이터가 비어 있으면 ValueError를 발생시킵니다.\n",
        "\n",
        "> 힌트: calc_min()과 유사하게 구현되지만, max()를 사용하여 가장 큰 숫자를 반환합니다.\n",
        "\n",
        "* calc_median(self): 숫자 데이터의 중앙값을 계산하고 반환합니다. 데이터를 정렬한 후 중앙값을 계산합니다. 데이터 포인트 수가 홀수인 경우 중간값을 반환하고, 짝수인 경우 두 중간값의 평균을 반환합니다.\n",
        "\n",
        "> 힌트: 데이터를 읽은 후 정렬하여 중앙값을 계산합니다. 데이터 길이가 짝수일 경우 중앙값은 두 중간 숫자의 평균이고, 홀수일 경우 중앙값은 중간 숫자입니다.\n",
        "\n",
        "### 오류 처리\n",
        "\n",
        "클래스는 파일을 찾을 수 없거나 파일에 유효하지 않은 데이터가 있을 때 적절한 예외를 발생시켜야 합니다.\n",
        "\n",
        "* FileNotFoundError: 파일이 존재하지 않을 때 발생합니다.\n",
        "* ValueError: 파일의 한 줄이 실수로 변환할 수 없거나 최소값, 최대값 또는 중앙값 작업에 대해 빈 파일이 제공될 때 발생합니다.\n",
        "* ZeroDivisionError: 파일이 비어 있어 평균을 계산할 데이터가 없을 때 발생합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UAF4rYtNqtF"
      },
      "outputs": [],
      "source": [
        "class FileProcessor:\n",
        "    def __init__(self, file_name: str):\n",
        "        pass\n",
        "\n",
        "    def __read_file(self):\n",
        "        pass\n",
        "\n",
        "    def calc_sum(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_average(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_min(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_max(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_median(self) -> float:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HB7gKAQOZs4"
      },
      "outputs": [],
      "source": [
        "input_files = ['./Numbers.txt', './EmptyFile.txt', './InvalidFile.txt']\n",
        "expected_sums = [23759.0, None, None]\n",
        "expected_averages = [475.2, None, None]\n",
        "expected_mins = [33.0, None, None]\n",
        "expected_maxs = [948.0, None, None]\n",
        "expected_medians = [442.5, None, None]\n",
        "\n",
        "failed_tests = []\n",
        "\n",
        "for file, expected_sum, expected_avg, expected_min, expected_max, expected_median in zip(input_files, expected_sums, expected_averages, expected_mins, expected_maxs, expected_medians):\n",
        "    processor = FileProcessor(file)\n",
        "\n",
        "    try:\n",
        "        result_sum = processor.calc_sum()\n",
        "        if expected_sum is not None:\n",
        "            assert round(result_sum, 1) == round(expected_sum, 1)\n",
        "    except (FileNotFoundError, ValueError, ZeroDivisionError) as e:\n",
        "        if expected_sum is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Sum test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_avg = processor.calc_average()\n",
        "        if expected_avg is not None:\n",
        "            assert round(result_avg, 1) == round(expected_avg, 1)\n",
        "    except (FileNotFoundError, ValueError, ZeroDivisionError) as e:\n",
        "        if expected_avg is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Average test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_min = processor.calc_min()\n",
        "        if expected_min is not None:\n",
        "            assert round(result_min, 1) == round(expected_min, 1)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        if expected_min is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Min test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_max = processor.calc_max()\n",
        "        if expected_max is not None:\n",
        "            assert round(result_max, 1) == round(expected_max, 1)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        if expected_max is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Max test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_median = processor.calc_median()\n",
        "        if expected_median is not None:\n",
        "            assert round(result_median, 1) == round(expected_median, 1)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        if expected_median is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Median test failed for {file}: {e}\")\n",
        "\n",
        "if failed_tests:\n",
        "    for test in failed_tests:\n",
        "        print(test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
